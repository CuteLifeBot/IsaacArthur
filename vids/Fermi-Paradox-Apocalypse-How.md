
---


---

Fermi Paradox Apocalypse How
---
  
2015-05-04  
https://youtu.be/zmbldpqn0K4  

---

In the previous video we outlined all the major solutions to the Fermi Paradox. 

**[00:00:15](https://youtube.com/watch?v=zmbldpqn0K4&t=00h00m15s)**  If you haven’t watched that yet, this video is meant as a stand alone, but it would probably help to watch that first. 

**[00:00:22](https://youtube.com/watch?v=zmbldpqn0K4&t=00h00m22s)**  As a reminder, the Fermi Paradox is the apparent contradiction between the seemingly high probability of alien civilizations existing and the total absence of any solid evidence that they do exist. 

**[00:00:33](https://youtube.com/watch?v=zmbldpqn0K4&t=00h00m33s)**  Or as Enrico Fermi put it, if there are tons of alien civilizations, “Where is everybody?” We outlined a lot of proposed solutions in that video from us just not knowing what to look for to find them to them going out of their way to hide themselves or us just refusing to believe evidence right under our noses. 

**[00:00:52](https://youtube.com/watch?v=zmbldpqn0K4&t=00h00m52s)**  However one of the more popular solutions revolves around the idea that alien civilizations are terribly uncommon, either because they rarely develop civilization or because they almost always go extinct. 

**[00:01:10](https://youtube.com/watch?v=zmbldpqn0K4&t=00h01m10s)**  Today we’ll be looking at the latter option. 

**[00:01:19](https://youtube.com/watch?v=zmbldpqn0K4&t=00h01m19s)**  If you’re alive, today, in the 21st century, and watching Youtube, then you have already been exposed to virtually ever apocalyptic scenario imaginable. 

**[00:01:28](https://youtube.com/watch?v=zmbldpqn0K4&t=00h01m28s)**  Hollywood does a wonderful job blowing stuff up for our entertainment. 

**[00:01:32](https://youtube.com/watch?v=zmbldpqn0K4&t=00h01m32s)**  We’re going to go over some of these and see how realistic they are. 

**[00:01:35](https://youtube.com/watch?v=zmbldpqn0K4&t=00h01m35s)**  But we’re not interested in some of these cases because they don’t really matter in terms of the Fermi Paradox. 

**[00:01:42](https://youtube.com/watch?v=zmbldpqn0K4&t=00h01m42s)**  For instance, portrayal of genetic superman wiping out mankind is really an irrelevancy as far as Fermi’s Paradox is concerned because highly aggressive genetic supermen are just as likely to go expanding out into the wider universe as we are. 

**[00:01:58](https://youtube.com/watch?v=zmbldpqn0K4&t=00h01m58s)**  Doomsday’s for humanity that replace us with another intelligence that has survival and propagation as motives just don’t matter for Fermi’s Paradox. 

**[00:02:08](https://youtube.com/watch?v=zmbldpqn0K4&t=00h02m08s)**  And as we previously discussed in the Dyson Dilemma video even a singular intelligence which didn’t want to reproduce has good motivations to expand itself. 

**[00:02:17](https://youtube.com/watch?v=zmbldpqn0K4&t=00h02m17s)**  We’re looking for something that ends civilization. 

**[00:02:22](https://youtube.com/watch?v=zmbldpqn0K4&t=00h02m22s)**  Not civilization as we know it, but just destroys any intelligence with the desire and capacity for expanding into space. 

**[00:02:30](https://youtube.com/watch?v=zmbldpqn0K4&t=00h02m30s)**  So for instance a swarm of self-replicating robots with the technology for interstellar travel but nothing approaching a civilization is a Fermi Paradox concern, alternatively a complex and ancient civilization which arose after a nuclear war and bans any 20th century technology and enforces those bans rigorously is not. 

**[00:02:54](https://youtube.com/watch?v=zmbldpqn0K4&t=00h02m54s)**  One could argue in that latter case though, that anyone who bans technology because of some cataclysmic event is going to have problems enforcing that over very long times. 

**[00:03:04](https://youtube.com/watch?v=zmbldpqn0K4&t=00h03m04s)**  Societies mutate on a generational basis, and especially without solid worldwide communications you’d expect to see a lot of schism and fracturing. 

**[00:03:14](https://youtube.com/watch?v=zmbldpqn0K4&t=00h03m14s)**  Even keeping an orthodoxy for a thus an years seems hard, but planets exist for billions of years and the simple fact is that, all things being equal, a group which starts ignoring the tech bans are going to start gaining a massive economic and military edge. 

**[00:03:36](https://youtube.com/watch?v=zmbldpqn0K4&t=00h03m36s)**  So we’re going to go over a lot of these doomsday scenarios and discussing not so much how likely they are to occur but how likely they are to take a civilization down entirely for keeps. 

**[00:03:50](https://youtube.com/watch?v=zmbldpqn0K4&t=00h03m50s)**  It’s hard to really classify civilization destroying events but we are going to give it a go. 

**[00:03:56](https://youtube.com/watch?v=zmbldpqn0K4&t=00h03m56s)**  Here’s the one’s I’ve selected are: Nuclear War Bioterrorism Post-Apocalyptic Attrition Cyclical Apocalypse Climate Change Artificial Intelligence Grey Goo Anti-Matter Suicide Pact Technology Mind Control One thing we’ll be mostly avoiding is social matters. 

**[00:04:28](https://youtube.com/watch?v=zmbldpqn0K4&t=00h04m28s)**  Not only are these hard to predict, and as we pointed out, prone to very rapid change on stellar timelines, but they get pretty controversial because they get political. 

**[00:04:38](https://youtube.com/watch?v=zmbldpqn0K4&t=00h04m38s)**  Everyone’s mileage varies on such things and there’s not really a rigorous approach available to analyze such things, so we’ll just leave it be so the comments section under the video doesn’t get full of invective. 

**[00:04:54](https://youtube.com/watch?v=zmbldpqn0K4&t=00h04m54s)**  By the way I do read all the comments on these videos and try to reply to them, so please feel free to leave a comment below. 

**[00:05:02](https://youtube.com/watch?v=zmbldpqn0K4&t=00h05m02s)**  So, Nuclear War. 

**[00:05:06](https://youtube.com/watch?v=zmbldpqn0K4&t=00h05m06s)**  This is one we’re all pretty familiar with but like a lot of disasters in movies it tends not to get portrayed very accurately. 

**[00:05:14](https://youtube.com/watch?v=zmbldpqn0K4&t=00h05m14s)**  Nuclear bombs are devastating, but fundamentally, even at the height of the cold war, there just weren’t enough to kill off civilization for keeps. 

**[00:05:27](https://youtube.com/watch?v=zmbldpqn0K4&t=00h05m27s)**  Nuclear bombs kill many, collapse present society, and leave long-lasting damage to the ecosystem. 

**[00:05:33](https://youtube.com/watch?v=zmbldpqn0K4&t=00h05m33s)**  However, they don’t get everybody, and in most estimates don’t even get half. 

**[00:05:39](https://youtube.com/watch?v=zmbldpqn0K4&t=00h05m39s)**  Starvation and chaos will get far more, but ironically are less of a threat the more people die initially. 

**[00:05:46](https://youtube.com/watch?v=zmbldpqn0K4&t=00h05m46s)**  We’ll cover this more in the Post-Apocalyptic Attrition segment but it basically boils down having some surviving settlements that eke their way through the centuries it takes for the planet to recover. 

**[00:05:57](https://youtube.com/watch?v=zmbldpqn0K4&t=00h05m57s)**  Fundamentally, just as with our own Dark Ages, these periods simply are very short compared to the timespan planets exist for. 

**[00:06:05](https://youtube.com/watch?v=zmbldpqn0K4&t=00h06m05s)**  If some world had beat us modern civilization by a mere million years, an eyeblink compared to the Age of the Universe, even if it took them a thousand years to recover from a nuclear was and even if they repeated the process 10 or 12 times before learning better, or running out of uranium, they’d still have burned up only a percent or two of their headstart on us. 

**[00:06:29](https://youtube.com/watch?v=zmbldpqn0K4&t=00h06m29s)**  Now a sufficiently large nuclear device, or nuclear arsenal, could kill everyone. 

**[00:06:34](https://youtube.com/watch?v=zmbldpqn0K4&t=00h06m34s)**  We can’t rule this out but there’s a host of hurdles to building an arsenal that’s simply far bigger than you need to destroy your enemy ten times over again. 

**[00:06:47](https://youtube.com/watch?v=zmbldpqn0K4&t=00h06m47s)**  Nukes are expensive to build and maintain, arsenals on that scale are basically deadman switches designed to convince an enemy that attacking is suicide, people are very interested in their own survival and would tend to build in massive safeguards. 

**[00:07:14](https://youtube.com/watch?v=zmbldpqn0K4&t=00h07m14s)**  We never built such things, odds are good few others would either and the Fermi Paradox is all about the odds. 

**[00:07:22](https://youtube.com/watch?v=zmbldpqn0K4&t=00h07m22s)**  If 1 species does this but 9 others don’t, it doesn’t really matter. 

**[00:07:33](https://youtube.com/watch?v=zmbldpqn0K4&t=00h07m33s)**  So fundamentally nuclear war, at least with the technology so far devised, isn’t a terribly good Fermi Paradox solution. 

**[00:07:43](https://youtube.com/watch?v=zmbldpqn0K4&t=00h07m43s)**  So what about biowarfare? 

**[00:07:45](https://youtube.com/watch?v=zmbldpqn0K4&t=00h07m45s)**  The same conditions apply to any virus that doesn’t get everyone, but we can’t rule out someone designing a virus that does get everyone. 

**[00:07:52](https://youtube.com/watch?v=zmbldpqn0K4&t=00h07m52s)**  And it really does need to get everyone. 

**[00:07:56](https://youtube.com/watch?v=zmbldpqn0K4&t=00h07m56s)**  If even 1 in a million are immune that still leaves thousands of people alive. 

**[00:08:03](https://youtube.com/watch?v=zmbldpqn0K4&t=00h08m03s)**  They’d be scattered all over but since vast amounts of technology and resources would be kicking around intact it would only be a matter of time before lonely people started making efforts to link up with each other. 

**[00:08:16](https://youtube.com/watch?v=zmbldpqn0K4&t=00h08m16s)**  When you’ve got months or years to contemplate the problem you don’t need to be a genius to think of lighting beacon fires on top of skyscrapers or using a radio tower to broadcast to others. 

**[00:08:30](https://youtube.com/watch?v=zmbldpqn0K4&t=00h08m30s)**  And that’s assuming no one had enough time during the crisis to start taking measures like telling the survivors how to link up or get people into a sealed environment with resource stockpiles. 

**[00:08:40](https://youtube.com/watch?v=zmbldpqn0K4&t=00h08m40s)**  And if the immunity was more like 1% you wouldn’t even need special measures to link people up into groups big enough to survive and breed. 

**[00:08:51](https://youtube.com/watch?v=zmbldpqn0K4&t=00h08m51s)**  So it would have to a 100% kill. 

**[00:08:57](https://youtube.com/watch?v=zmbldpqn0K4&t=00h08m57s)**  And that’s not really a natural or accidental lab accident sort of result. 

**[00:09:01](https://youtube.com/watch?v=zmbldpqn0K4&t=00h09m01s)**  You’d almost have to have a large and well-funded group set out to intentionally kill every single person on the planet. 

**[00:09:07](https://youtube.com/watch?v=zmbldpqn0K4&t=00h09m07s)**  Outside of Hollywood that’s not terrible tenable. 

**[00:09:11](https://youtube.com/watch?v=zmbldpqn0K4&t=00h09m11s)**  The bigger the group, the better the odds of someone changing their mind and informing authorities. 

**[00:09:15](https://youtube.com/watch?v=zmbldpqn0K4&t=00h09m15s)**  Even if we grant all that though, we still have three problems in the context of the Fermi Paradox. 

**[00:09:21](https://youtube.com/watch?v=zmbldpqn0K4&t=00h09m21s)**  First, not every alien species is likely to do this. 

**[00:09:25](https://youtube.com/watch?v=zmbldpqn0K4&t=00h09m25s)**  Just like with nuclear war, it doesn’t matter if 1 in 10 does if 9 in 10 don’t, and even if it were 9 in 10, or 99 in 100 that did this it still wouldn’t really matter much to the Fermi Paradox because if you have a thousand or so civilizations arising in a billion years per galaxy even if 99.9% did this to themselves you’d still have one left over who didn’t. 

**[00:10:02](https://youtube.com/watch?v=zmbldpqn0K4&t=00h10m02s)**  Second, when we’re working in the context that intelligence tends to develop fairly commonly, then wipe itself out, which is what Doomsday approaches to the Fermi Paradox revolve around, then wiping out all humans with a virus would still leave other intelligent mammals around who would, if intelligence evolving is common, replace us. 

**[00:10:21](https://youtube.com/watch?v=zmbldpqn0K4&t=00h10m21s)**  It might take a million years, or ten million years, or even a hundred million years but even a hundred million years isn’t that long compared to the age of the Universe or this planet. 

**[00:10:30](https://youtube.com/watch?v=zmbldpqn0K4&t=00h10m30s)**  It’s around 1%. 

**[00:10:32](https://youtube.com/watch?v=zmbldpqn0K4&t=00h10m32s)**  Third, we also have to remember that viruses might not really be a universal threat. 

**[00:10:36](https://youtube.com/watch?v=zmbldpqn0K4&t=00h10m36s)**  Viruses are present in, and a threat to, every environment and organism on Earth. 

**[00:10:41](https://youtube.com/watch?v=zmbldpqn0K4&t=00h10m41s)**  But that doesn’t mean they’d be an automatic threat in all life-bearing worlds to the degree they are to us. 

**[00:10:46](https://youtube.com/watch?v=zmbldpqn0K4&t=00h10m46s)**  A given species might have much more effective immune systems or a biology which is just very toughened against dying from infection. 

**[00:10:53](https://youtube.com/watch?v=zmbldpqn0K4&t=00h10m53s)**  So this type of apocalypse also isn’t’ a really good Fermi Paradox solution. 

**[00:11:00](https://youtube.com/watch?v=zmbldpqn0K4&t=00h11m00s)**  This takes us to Post-Apocalyptic Attrition, which is less of a specific Apocalypse and more about recovery. 

**[00:11:09](https://youtube.com/watch?v=zmbldpqn0K4&t=00h11m09s)**  One common theme of disasters is that you often get more damage done in the aftermath than the actual incident itself. 

**[00:11:15](https://youtube.com/watch?v=zmbldpqn0K4&t=00h11m15s)**  In fiction in particularly we’ll have rioting mobs or in the aftermath roving brigands who basically steal to live and destroy any stable bastions of civilization they encounter. 

**[00:11:25](https://youtube.com/watch?v=zmbldpqn0K4&t=00h11m25s)**  This results in a steady attrition just pushing us down till no one is left. 

**[00:11:29](https://youtube.com/watch?v=zmbldpqn0K4&t=00h11m29s)**  Now the problem here is you can only kill so many people before theft-to-live is no longer viable. 

**[00:11:35](https://youtube.com/watch?v=zmbldpqn0K4&t=00h11m35s)**  Once your numbers get down to hunter-gatherer levels, a few square miles per person, it now is not only no longer necessary to kill people to get food but also a bad strategy. 

**[00:11:46](https://youtube.com/watch?v=zmbldpqn0K4&t=00h11m46s)**  Deer won’t shoot you, and if all that’s left of civilization are the people who’ve survived the bloodbath odds are good those survivors can and will shoot you. 

**[00:11:57](https://youtube.com/watch?v=zmbldpqn0K4&t=00h11m57s)**  You’ve also got the problem that an organized and disciplined group that’s been keeping around people who have other values besides fighting, like repairing stuff and treating injuries, is going to butcher the stereotypical post-apocalyptic Mad Max tribe of techno-savages in a fight. 

**[00:12:17](https://youtube.com/watch?v=zmbldpqn0K4&t=00h12m17s)**  So eventually attrition slows down, and it is basically bound to do this while the numbers are still high enough that people still regularly encounter each other so you really can’t push a population down below breeding-level viability through attrition. 

**[00:12:30](https://youtube.com/watch?v=zmbldpqn0K4&t=00h12m30s)**  After a while, even if they’ve lost all their technology, and especially if they lost it all, they just revert to hunter gather tribes. 

**[00:12:38](https://youtube.com/watch?v=zmbldpqn0K4&t=00h12m38s)**  A setback, but presumably of thousands of years at most. 

**[00:12:42](https://youtube.com/watch?v=zmbldpqn0K4&t=00h12m42s)**  And it would probably be a lot less, because examples of technology, rusty or not, are going to be lying around everywhere and you can fit pretty much every major bit of science and technology up to the 20th century into books which would take up a small chest. 

**[00:12:57](https://youtube.com/watch?v=zmbldpqn0K4&t=00h12m57s)**  Heck you can download the entire Wikipedia database free of charge onto a single thumb drive. 

**[00:13:03](https://youtube.com/watch?v=zmbldpqn0K4&t=00h13m03s)**  But you’d be bound to have caches set aside by people of this variety and even if you didn’t you don’t need to be nearly as smart as the guys who designed the internal combustion engine to reverse engineer it from some rusty remnant. 

**[00:13:15](https://youtube.com/watch?v=zmbldpqn0K4&t=00h13m15s)**  Our own buried landfills, unlikely to be pillaged in an apocalyptic aftermath, would contain everything you needed. 

**[00:13:23](https://youtube.com/watch?v=zmbldpqn0K4&t=00h13m23s)**  So you would expect civilization to recover eventually, and sooner than later, in any doomsday which left enough of us alive to breed and was still ecologically intact enough to support life. 

**[00:13:36](https://youtube.com/watch?v=zmbldpqn0K4&t=00h13m36s)**  But having killed themselves once, what’s stopping them from doing it again? 

**[00:13:40](https://youtube.com/watch?v=zmbldpqn0K4&t=00h13m40s)**  Cyclical apocalypses, natural or unnatural, are a real concern. 

**[00:13:45](https://youtube.com/watch?v=zmbldpqn0K4&t=00h13m45s)**  We’ve got some great examples of this in fiction (Pern, Nightfall, Mote in God’s Eye) and of course these being fiction tend to either focus on breaking the recurring cycle or if more bleak and dark, on the futility of trying breaking out of the cycle. 

**[00:13:59](https://youtube.com/watch?v=zmbldpqn0K4&t=00h13m59s)**  But how probable is this? 

**[00:14:01](https://youtube.com/watch?v=zmbldpqn0K4&t=00h14m01s)**  That’s really hard to say. 

**[00:14:03](https://youtube.com/watch?v=zmbldpqn0K4&t=00h14m03s)**  If a civilization arises, nukes itself nearly out of existence, recovers over thousands of years, then does it again, what’s to stop them doing it again, and again, and again? 

**[00:14:15](https://youtube.com/watch?v=zmbldpqn0K4&t=00h14m15s)**  Well I mentioned half-jokingly early you’d eventually run out of enriched uranium to build nukes with. 

**[00:14:21](https://youtube.com/watch?v=zmbldpqn0K4&t=00h14m21s)**  Radioactive isotopes decay with time, that’s why they are rare to begin with, not much left over from the ancient supernovas that spawned them, and if you’ve being mining every source of them for cycles of nuclear warfare you will run out. 

**[00:14:39](https://youtube.com/watch?v=zmbldpqn0K4&t=00h14m39s)**  But fundamentally its really hard to eliminate all traces of a civilization. 

**[00:14:49](https://youtube.com/watch?v=zmbldpqn0K4&t=00h14m49s)**  Even if every single historical account is burned or bastardized into mythology that barely resembles what really happened you going to start having increasing amounts of archeological and even geological records. 

**[00:15:02](https://youtube.com/watch?v=zmbldpqn0K4&t=00h15m02s)**  It would be hard to miss evidence that every ten thousand or so years for the last couple million years civilization had gotten technological then knocked itself back to primitive hunter-gatherer remnants. 

**[00:15:12](https://youtube.com/watch?v=zmbldpqn0K4&t=00h15m12s)**  And even that’s a pretty unrealistic scenario. 

**[00:15:16](https://youtube.com/watch?v=zmbldpqn0K4&t=00h15m16s)**  We really do have bunker-archives, even back to the Crypt of Civilization built in Georgia in 1936, which would be usable guides to reforging civilization even thousands of years after they were built. 

**[00:15:28](https://youtube.com/watch?v=zmbldpqn0K4&t=00h15m28s)**  These sorts of time-capsules and caches probably would survive almost any doomsday scenario that left people alive. 

**[00:15:35](https://youtube.com/watch?v=zmbldpqn0K4&t=00h15m35s)**  If you’re pessimist you can come up with ways these might fail to survive or just be disbelieved but intelligent critters are usually very survival oriented and it’s hard for me, personally, to imagine such cycles just going on and on uninterrupted for thousands of cycles till the world got burned up by the sun. 

**[00:16:01](https://youtube.com/watch?v=zmbldpqn0K4&t=00h16m01s)**  Our next one is climate change. 

**[00:16:03](https://youtube.com/watch?v=zmbldpqn0K4&t=00h16m03s)**  This is politically controversial so we’re going to keep this short, like I said I like people to leave me comments on the videos but I don’t invite invective. 

**[00:16:13](https://youtube.com/watch?v=zmbldpqn0K4&t=00h16m13s)**  Please take pro or anti climate change arguments elsewhere, plenty of other places to talk about that. 

**[00:16:20](https://youtube.com/watch?v=zmbldpqn0K4&t=00h16m20s)**  Global warming for this is pretty straight forward anyway. 

**[00:16:26](https://youtube.com/watch?v=zmbldpqn0K4&t=00h16m26s)**  It is possible climate change could leave a world dead, rendered either as a snowball Earth or Runaway Greenhouse Venus setup. 

**[00:16:36](https://youtube.com/watch?v=zmbldpqn0K4&t=00h16m36s)**  We don’t know. 

**[00:16:38](https://youtube.com/watch?v=zmbldpqn0K4&t=00h16m38s)**  If  this is possible then everybody’s dead and it’s a decent Fermi Paradox option. 

**[00:16:53](https://youtube.com/watch?v=zmbldpqn0K4&t=00h16m53s)**  Except that it would require every species does let this happen and that’s counter-indicated because even if they all would, its not really a given all could. 

**[00:17:02](https://youtube.com/watch?v=zmbldpqn0K4&t=00h17m02s)**  Our fossils fuels are the product of a very long and complex geological process. 

**[00:17:10](https://youtube.com/watch?v=zmbldpqn0K4&t=00h17m10s)**  Underwater oil deposits often rupture and leak out, underground coal seams can burn. 

**[00:17:16](https://youtube.com/watch?v=zmbldpqn0K4&t=00h17m16s)**  So there’s really nothing saying every world would have as much of these items as we do when technological life arose. 

**[00:17:24](https://youtube.com/watch?v=zmbldpqn0K4&t=00h17m24s)**  They might be immune to the problem because they don’t much. 

**[00:17:31](https://youtube.com/watch?v=zmbldpqn0K4&t=00h17m31s)**  Plus the individual configurations of the planets, its distance from the sun, its type of sun, i’s own default atmosphere, and so on, might make it immune to such problems. 

**[00:17:45](https://youtube.com/watch?v=zmbldpqn0K4&t=00h17m45s)**  They might live on a world with a dozen times more atmospheric carbon then we already have and that’s what lets it be warm enough for life. 

**[00:17:54](https://youtube.com/watch?v=zmbldpqn0K4&t=00h17m54s)**  Their world might be very prone to earthquakes compared to us and all the easy deposits of fuels ruptured. 

**[00:18:03](https://youtube.com/watch?v=zmbldpqn0K4&t=00h18m03s)**  Add to that, if it wouldn’t wipe out all life but was recoverable over time, then civilization would recover and wouldn’t have those deposits for technology round 2. 

**[00:18:17](https://youtube.com/watch?v=zmbldpqn0K4&t=00h18m17s)**  Now that’s a problem because we used those to get to our present technological state, but we did have renewable fuels before we used these, like alcohol or ethanol, firewood, and so on. 

**[00:18:31](https://youtube.com/watch?v=zmbldpqn0K4&t=00h18m31s)**  You can’t support as many people in the short term, and fuel is more expensive, but this probably would just slow technological process, not halt it. 

**[00:18:40](https://youtube.com/watch?v=zmbldpqn0K4&t=00h18m40s)**  And again centuries or even tens of thousands of years mean nothing in the timeline of the universe. 

**[00:18:45](https://youtube.com/watch?v=zmbldpqn0K4&t=00h18m45s)**  So this also isn’t a good Fermi-Paradox solution. 

**[00:18:50](https://youtube.com/watch?v=zmbldpqn0K4&t=00h18m50s)**  Our next one, Artificial Intelligence, also really isn’t. 

**[00:18:56](https://youtube.com/watch?v=zmbldpqn0K4&t=00h18m56s)**  As we mentioned earlier and in previous videos, replacing one intelligence with another doesn’t mean anything to the Fermi Paradox unless its motives are so different that it doesn’t act in any way which would emulate either of the three basically universal rules of natural life. 

**[00:19:15](https://youtube.com/watch?v=zmbldpqn0K4&t=00h19m15s)**  That it very focused on surviving, that it wants to reproduce, and that it wants to expand its resources and territory. 

**[00:19:24](https://youtube.com/watch?v=zmbldpqn0K4&t=00h19m24s)**  An AI which didn’t care about tis own survival isn’t likely to replace the species that birthed it, and we discussed in the Dyson Dilemma video why even one which didn’t want to reproduce itself would still tend to functionally emulate an expanding and growing species. 

**[00:19:43](https://youtube.com/watch?v=zmbldpqn0K4&t=00h19m43s)**  So AI really only matters in the sense of being an apocalypse which kills it and us. 

**[00:19:50](https://youtube.com/watch?v=zmbldpqn0K4&t=00h19m50s)**  The big problem with this is that an AI which is smarter than us, a Strong AI, is smarter than us. 

**[00:19:56](https://youtube.com/watch?v=zmbldpqn0K4&t=00h19m56s)**  In Hollywood these AI’s run numbers quickly but are generally absolute morons when it comes to social interaction. 

**[00:20:06](https://youtube.com/watch?v=zmbldpqn0K4&t=00h20m06s)**  A real strong AI probably isn’t going to scare us because it will be smart enough to emulate a very pleasant, helpful, and non-threatening friend. 

**[00:20:13](https://youtube.com/watch?v=zmbldpqn0K4&t=00h20m13s)**  An AI planning to take over the world is probably a lot more likely to get the courts to rule it legally a person and convince people to vote it president in landslide election then to go all SkyNet or Matrix on us. 

**[00:20:35](https://youtube.com/watch?v=zmbldpqn0K4&t=00h20m35s)**  If it wants us all dead, we’d probably never know it till it acted and the outcome would be about as predetermined as fighting off an alien invasion by a species set on genocide and capable of interstellar travel. 

**[00:20:49](https://youtube.com/watch?v=zmbldpqn0K4&t=00h20m49s)**  Which is to say the ‘battle’ would last about ten minutes. 

**[00:20:53](https://youtube.com/watch?v=zmbldpqn0K4&t=00h20m53s)**  Which is to say, you don’t beat a smarter, bigger, more technologically advanced group in a one-on-one fight unless its goal isn’t to kill you in the first place. 

**[00:21:04](https://youtube.com/watch?v=zmbldpqn0K4&t=00h21m04s)**  If it just wants you dead, and doesn’t care about the property damage, an interstellar ship doesn’t even need to fire any guns. 

**[00:21:10](https://youtube.com/watch?v=zmbldpqn0K4&t=00h21m10s)**  It just has to jettison some of its mass aimed at Earth before it starts slowing down. 

**[00:21:15](https://youtube.com/watch?v=zmbldpqn0K4&t=00h21m15s)**  Because a few thousands tons of garbage moving at relativistic speeds and hitting Earth would make a nuclear war look like a barroom scuffle in comparison. 

**[00:21:24](https://youtube.com/watch?v=zmbldpqn0K4&t=00h21m24s)**  A machine doesn’t need an intact biosphere to live so it can go all scorched Earth. 

**[00:21:29](https://youtube.com/watch?v=zmbldpqn0K4&t=00h21m29s)**  Hard to beat an enemy who is smarter than you and has a much freer hand where collateral damage is concerned. 

**[00:21:36](https://youtube.com/watch?v=zmbldpqn0K4&t=00h21m36s)**  So it’s really unlikely a fight with a machine mind would end in a mutual kill, and the survivor would pick itself up and recover, not a good Fermi Paradox option. 

**[00:21:49](https://youtube.com/watch?v=zmbldpqn0K4&t=00h21m49s)**  Alternatively a stupid machine is. 

**[00:21:51](https://youtube.com/watch?v=zmbldpqn0K4&t=00h21m51s)**  Grey Goo as its often called, microscopic little machines which are simply programmed to tear everything apart to make more of themselves, is an apocalypse scenario which fits into the Fermi Paradox. 

**[00:22:02](https://youtube.com/watch?v=zmbldpqn0K4&t=00h22m02s)**  Though only if they’re too dumb to make it off world. 

**[00:22:09](https://youtube.com/watch?v=zmbldpqn0K4&t=00h22m09s)**  This is a lot like the biowarfare option only far worse because there’s no immunity to being disassembled as scrap by a billion little robots who also disassemble all the animals, vegetables, and minerals. 

**[00:22:21](https://youtube.com/watch?v=zmbldpqn0K4&t=00h22m21s)**  So Grey Goo is a real concern. 

**[00:22:25](https://youtube.com/watch?v=zmbldpqn0K4&t=00h22m25s)**  Two caveats in the context of the Fermi Paradox though. 

**[00:22:28](https://youtube.com/watch?v=zmbldpqn0K4&t=00h22m28s)**  First, there’s no reason to assume that even if Grey Goo starts off mindless it would stay that way. 

**[00:22:35](https://youtube.com/watch?v=zmbldpqn0K4&t=00h22m35s)**  We, ourselves, are essentially descended from Grey Goo. 

**[00:22:38](https://youtube.com/watch?v=zmbldpqn0K4&t=00h22m38s)**  Early life just mindlessly ate anything it could to reproduce. 

**[00:22:42](https://youtube.com/watch?v=zmbldpqn0K4&t=00h22m42s)**  It mutated and grew in complexity. 

**[00:22:45](https://youtube.com/watch?v=zmbldpqn0K4&t=00h22m45s)**  Grey Goo would also likely be capable of mutation, it’s basically unavoidable in replicating life or machines. 

**[00:22:55](https://youtube.com/watch?v=zmbldpqn0K4&t=00h22m55s)**  Now Grey Goo reproduces a lot faster than biological life, if it didn’t it wouldn’t be a threat. 

**[00:23:01](https://youtube.com/watch?v=zmbldpqn0K4&t=00h23m01s)**  So it might climb the evolutionary chain to intelligence much faster. 

**[00:23:07](https://youtube.com/watch?v=zmbldpqn0K4&t=00h23m07s)**  Of course it might be exponentially less prone to mutation too which might cause the reverse. 

**[00:23:12](https://youtube.com/watch?v=zmbldpqn0K4&t=00h23m12s)**  But from a certain light Grey Goo is just a life reset akin to when oxygen breathers became the norm for life on Earth. 

**[00:23:21](https://youtube.com/watch?v=zmbldpqn0K4&t=00h23m21s)**  The other caveat is that self-replicating machines are probably not the boogey-man we make them out to be. 

**[00:23:26](https://youtube.com/watch?v=zmbldpqn0K4&t=00h23m26s)**  Just because something can replicate faster than biological life doesn’t mean it can replicate absurdly quickly. 

**[00:23:32](https://youtube.com/watch?v=zmbldpqn0K4&t=00h23m32s)**  There’s waste heat involved in any mechanical process. 

**[00:23:35](https://youtube.com/watch?v=zmbldpqn0K4&t=00h23m35s)**  Try bending a metal coat hanger back and forth several times quickly till it breaks and sticking your finger at the snap point. 

**[00:23:48](https://youtube.com/watch?v=zmbldpqn0K4&t=00h23m48s)**  You’ll burn your hand. 

**[00:23:49](https://youtube.com/watch?v=zmbldpqn0K4&t=00h23m49s)**  They’d be limited to how fast they could rip stuff apart without melting themselves. 

**[00:23:53](https://youtube.com/watch?v=zmbldpqn0K4&t=00h23m53s)**  Second, you’re probably aware that electronic devices are sensitive to EMP bursts. 

**[00:23:59](https://youtube.com/watch?v=zmbldpqn0K4&t=00h23m59s)**  You can harden electronics against this but only to a point. 

**[00:24:04](https://youtube.com/watch?v=zmbldpqn0K4&t=00h24m04s)**  Especially with tiny machines adding in all that shielding is just going to slow its ability to reproduce down because now it needs more resources for each new machine and more time to make it and fewer can cluster together for each disassembly. 

**[00:24:24](https://youtube.com/watch?v=zmbldpqn0K4&t=00h24m24s)**  If they’re dumb, you can fight them, if they’re smart, they’re wired together as a group consciousness, which makes them smart and thus not a Fermi Paradox solution, and also makes them sensitive to signal jamming too. 

**[00:24:51](https://youtube.com/watch?v=zmbldpqn0K4&t=00h24m51s)**  So you probably can’t end the world from someone accidentally dropping a vial of the things to shatter on the concrete and go on a blitzkrieg. 

**[00:25:02](https://youtube.com/watch?v=zmbldpqn0K4&t=00h25m02s)**  You can also nuke them. 

**[00:25:05](https://youtube.com/watch?v=zmbldpqn0K4&t=00h25m05s)**  Nukes beat matter every time. 

**[00:25:08](https://youtube.com/watch?v=zmbldpqn0K4&t=00h25m08s)**  Nuclear forces and energies are just orders of magnitude more powerful then chemical bonds that bind matter. 

**[00:25:13](https://youtube.com/watch?v=zmbldpqn0K4&t=00h25m13s)**  That takes us to our next one. 

**[00:25:16](https://youtube.com/watch?v=zmbldpqn0K4&t=00h25m16s)**  If there’s one thing out their nastier than nuclear bombs in destructive potential its anti-matter. 

**[00:25:23](https://youtube.com/watch?v=zmbldpqn0K4&t=00h25m23s)**  A baseball size and mass of antimatter, dropped to the ground, would go off with a destructive blast on par with the largest nuclear devices we’ve ever made. 

**[00:25:33](https://youtube.com/watch?v=zmbldpqn0K4&t=00h25m33s)**  They release all their mass energy, whereas nukes release not even a percent of theirs. 

**[00:25:38](https://youtube.com/watch?v=zmbldpqn0K4&t=00h25m38s)**  This is exactly what makes interstellar ships so dangerous and why hard science fiction fans often chuckle the notion of an ‘unarmed ship’. 

**[00:25:46](https://youtube.com/watch?v=zmbldpqn0K4&t=00h25m46s)**  Anything going out at those kind of speeds is worth more than its weight in nukes in destructive power because the energies involved in those kind of speeds parallel mass energy, Einstein’s famous E-mc-squared. 

**[00:26:06](https://youtube.com/watch?v=zmbldpqn0K4&t=00h26m06s)**  You could blow up a fair sized city with just the antimatter that would fit inside a ballpoint pen’s interior. 

**[00:26:21](https://youtube.com/watch?v=zmbldpqn0K4&t=00h26m21s)**  So as a Fermi-paradox solution we’d have to consider what would happen if this substance became very easy to manufacture and hide. 

**[00:27:02](https://youtube.com/watch?v=zmbldpqn0K4&t=00h27m02s)**  Right now anti-matter is very hard to make. 

**[00:27:05](https://youtube.com/watch?v=zmbldpqn0K4&t=00h27m05s)**  As powerful as it is a single gram, the mass of a pea, is parallel to the Hiroshima bomb. 

**[00:27:13](https://youtube.com/watch?v=zmbldpqn0K4&t=00h27m13s)**  But it is so hard to make it would take us a billion years at present production to make that gram and we would have no way to store it. 

**[00:27:31](https://youtube.com/watch?v=zmbldpqn0K4&t=00h27m31s)**  That could change, we could find a way to produce it and store it cheaply and efficiently and covertly and that would make it the ultimate terrorist device. 

**[00:27:39](https://youtube.com/watch?v=zmbldpqn0K4&t=00h27m39s)**  Now, we’re not doing a separate section on 3D printing but 3D printing, while a marvel, comes with some attached concerns. 

**[00:27:50](https://youtube.com/watch?v=zmbldpqn0K4&t=00h27m50s)**  In theory, when fully developed, you can produce anything at home if you have the template. 

**[00:27:55](https://youtube.com/watch?v=zmbldpqn0K4&t=00h27m55s)**  So easy availability by lone crackpots to anti-matter, to 3D printers that could fabricate destructive devices, and so on, could make it virtually impossible to maintain a technological civilization because it becomes too easy for lone members to damage it and we have no shortage of lunatics. 

**[00:28:16](https://youtube.com/watch?v=zmbldpqn0K4&t=00h28m16s)**  This becomes a possible Fermi Paradox solution in the sense of species having to step back because they just can’t maintain technological infrastructure to support interstellar travel without being constantly vulnerable to their own crazy persons wreaking disproportionate destruction. 

**[00:28:32](https://youtube.com/watch?v=zmbldpqn0K4&t=00h28m32s)**  Our last category, mind control, will ponder that some more, but we have one other category first, and like antimatter it revolves around very powerful energy sources. 

**[00:28:46](https://youtube.com/watch?v=zmbldpqn0K4&t=00h28m46s)**  Suicide Pact Technology is essentially any tech that just by using it guarantees destruction. 

**[00:28:53](https://youtube.com/watch?v=zmbldpqn0K4&t=00h28m53s)**  Some people say that internal combustion engines or antibiotics or nuclear power or computers are these things. 

**[00:29:01](https://youtube.com/watch?v=zmbldpqn0K4&t=00h29m01s)**  This category in this video though refers more to technologies that look too good to be true and turn out to be apocalyptic. 

**[00:29:09](https://youtube.com/watch?v=zmbldpqn0K4&t=00h29m09s)**  You might remember some years back the concern people had about the CERN supercollider making a black hole that would sink the center of the earth and gobble up the planet. 

**[00:29:19](https://youtube.com/watch?v=zmbldpqn0K4&t=00h29m19s)**  I’m not going to address all the flaws in that idea but let’s hypothesize someone invented some powerplant that sucked energy out of seemingly nowhere for free. 

**[00:29:29](https://youtube.com/watch?v=zmbldpqn0K4&t=00h29m29s)**  Unbeknownst to them this really cool device sets off a ticking time bomb that blows the planet to smithereens a year after use in a way no one can foresee. 

**[00:29:40](https://youtube.com/watch?v=zmbldpqn0K4&t=00h29m40s)**  If the physics allowing this device were almost impossible not to discover before space travel was really practical, like how you almost can’t avoid discovering computers before you can make orbital satellites, then every species figures it out, uses it, and blows themselves up before they can expand into the stars. 

**[00:29:57](https://youtube.com/watch?v=zmbldpqn0K4&t=00h29m57s)**  Total Fermi Paradox solution. 

**[00:30:19](https://youtube.com/watch?v=zmbldpqn0K4&t=00h30m19s)**  And  again some feel computers, and AI, are an example of this. 

**[00:30:28](https://youtube.com/watch?v=zmbldpqn0K4&t=00h30m28s)**  Or fossil fuels. 

**[00:30:29](https://youtube.com/watch?v=zmbldpqn0K4&t=00h30m29s)**  Or Nukes. 

**[00:30:30](https://youtube.com/watch?v=zmbldpqn0K4&t=00h30m30s)**  As we’ve been discussing throughout the video. 

**[00:30:34](https://youtube.com/watch?v=zmbldpqn0K4&t=00h30m34s)**  Suicide Pact Technology isn’t a specific apocalypse but the notion of a technology that unavoidable kills its users and unavoidably gets discovered soon enough to kill them. 

**[00:30:45](https://youtube.com/watch?v=zmbldpqn0K4&t=00h30m45s)**  How plausible is this? 

**[00:30:47](https://youtube.com/watch?v=zmbldpqn0K4&t=00h30m47s)**  Well, like any Fermi Paradox solution we have to consider if it covers all the bases. 

**[00:30:52](https://youtube.com/watch?v=zmbldpqn0K4&t=00h30m52s)**  WE haven’t discovered any technology to the point of definite death yet and we really could build a Moon Base or Mars Base if we wanted, probably one that could keep going even if Earth ceased to exist. 

**[00:31:08](https://youtube.com/watch?v=zmbldpqn0K4&t=00h31m08s)**  And other alien worlds might have their interplanetary neighbors be closer, might have lower gravity or thinner air to make orbital launch easier. 

**[00:31:21](https://youtube.com/watch?v=zmbldpqn0K4&t=00h31m21s)**  So  besides us having nor real reason to believe there’s any Suicide Pact Technology that can and will always destroy a world there would probably be examples of critters who had reached our effective technological level and already gotten a splinter colony on another world in their system. 

**[00:31:50](https://youtube.com/watch?v=zmbldpqn0K4&t=00h31m50s)**  So even this isn’t really a great Fermi Paradox Solution. 

**[00:32:00](https://youtube.com/watch?v=zmbldpqn0K4&t=00h32m00s)**  Our last category is mind control. 

**[00:32:02](https://youtube.com/watch?v=zmbldpqn0K4&t=00h32m02s)**  As we mentioned in the anti-matter section you’ve got to worry, inside a technological civilization, about crazy individuals being able to wreak vast damage. 

**[00:32:13](https://youtube.com/watch?v=zmbldpqn0K4&t=00h32m13s)**  One solution to that, if you have the technology, would be to have a total big brother state or even outright mind control. 

**[00:32:25](https://youtube.com/watch?v=zmbldpqn0K4&t=00h32m25s)**  And certainly there are even more sinister reasons someone might want to use this sort of technology. 

**[00:32:30](https://youtube.com/watch?v=zmbldpqn0K4&t=00h32m30s)**  Now in of itself this is irrelevant to the Fermi Paradox. 

**[00:32:40](https://youtube.com/watch?v=zmbldpqn0K4&t=00h32m40s)**  But specific types of mind control would be. 

**[00:32:47](https://youtube.com/watch?v=zmbldpqn0K4&t=00h32m47s)**  For instance, a culture that’s gotten burned by technology might use mind control to permanently lock technological progress at a ‘safe’ level too low for interstellar travel. 

**[00:32:58](https://youtube.com/watch?v=zmbldpqn0K4&t=00h32m58s)**  Or, similarly, they might outright ban expansion because they can’t reliable maintain that enforced orthodoxy over light years of space and communication lag. 

**[00:33:08](https://youtube.com/watch?v=zmbldpqn0K4&t=00h33m08s)**  They don’t trust any colony not to splinter off and become a threat down the road. 

**[00:33:16](https://youtube.com/watch?v=zmbldpqn0K4&t=00h33m16s)**  It’s very hard to rule two islands, so to speak, because one of those islands will constantly be wanting to break free and maybe that potential threat just isn’t worth the risk for the resources it brings you, and interstellar space isn’t a planet, moving resources is a hugely long and hard process. 

**[00:33:36](https://youtube.com/watch?v=zmbldpqn0K4&t=00h33m36s)**  So  any sort of mind control or social control that results in motives not to expand and could reliably keep enforcing that for millions of years is a valid Fermi Paradox solution but only where there’s a universal motive, since it has to be all or nearly all aliens doing it, and that would rally only apply where there was a clear suicide pact technology on the horizon. 

**[00:34:07](https://youtube.com/watch?v=zmbldpqn0K4&t=00h34m07s)**  So there we go. 

**[00:34:09](https://youtube.com/watch?v=zmbldpqn0K4&t=00h34m09s)**  In summary, we looked at possible doomsday scenarios for what might take out intelligent life and we’ve seen that there’s not many good fits, in terms of the Fermi Paradox, for things which would get most let alone all intelligent species. 

**[00:34:21](https://youtube.com/watch?v=zmbldpqn0K4&t=00h34m21s)**  I hope you’ve enjoyed this video, fell free to check out some of my others or leave comments below. 

**[00:34:28](https://youtube.com/watch?v=zmbldpqn0K4&t=00h34m28s)**  Thanks for Watching and have a Great Day! 





